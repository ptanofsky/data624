---
title: "DATA 624 Assignment 5"
subtitle: "CUNY Fall 2021"
author: "Philip Tanofsky"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r warning=F, message=F}
# Import required R libraries
library(fpp3)
```

# Exercise 8.1

Consider the the number of pigs slaughtered in Victoria, available in the `aus_livestock` dataset.

## Section a

Use the `ETS()` function to estimate the equivalent model for simple exponential smoothing. Find the optimal values of $\alpha$ and $\ell_{0}$, and generate forecasts for the next four months.

```{r warning=F, message=F}
vic_pigs <- aus_livestock %>%
  filter(State == 'Victoria',
           Animal == 'Pigs')
# Estimate parameters
fit <- vic_pigs %>%
  model(ETS(Count ~ error("A") + trend("N") + season("N")))

# Output model fit
report(fit)
```

**Results:** Optimal values based on the simple exponential smoothing of `ETS()` function are $\alpha$ equal to 0.32 and $\ell_{0}$ equal to 100646.6

```{r warning=F, message=F}
fc <- fit %>%
  forecast(h = 4)

fc
```

Above output shows the forecasted value for the next 4 months, which is the same value: 95187.

```{r warning=F, message=F}
vic_pigs_2010 <- vic_pigs %>%
  filter(year(Month) > 2009)

fc %>%
  autoplot(vic_pigs_2010) +
  labs(y="Count", title="Pigs Slaughtered: Victoria") +
  guides(colour = "none")
```

The above plot shows the forecasted value for the next 4 months. Note: the data has been truncated so as to better show the forecasted values in context. Given the values are the same, the forecast line is horizontal.

## Section b

Compute a 95% prediction interval for the first forecast using $\hat{y} \pm 1.96s$ where $s$ is the standard deviation of the residuals. Compare your interval with the interval produced by R.

```{r warning=F, message=F}
# y-hat is the predicted value (.mean)
y_hat <- mean(fc$.mean[1])

# Apply augment function to get the residuals
aug_fit <- augment(fit)

# Calculate standard deviation based on the residuals from augment
s <- sd(aug_fit$.resid)

# Calculate the 95% prediction intervals
upper_limit_95 <- y_hat + (s * 1.96)
lower_limit_95 <- y_hat - (s * 1.96)

int_95 <- c(lower_limit_95, upper_limit_95)

# Output calculated interval values
int_95
```

Above is the calculated lower and upper limite for the 95% confidence interval.

```{r warning=F, message=F}
# Determine the model forecast 95% intervals
fc_hilo <- fc %>% hilo()

# Output model interval values
fc_hilo$`95%`[1]
```

Above is the interval produced by R.

The model low value is 16.22 lower than my calculated low interval value. The model high value is 16.2 higher than my calculate high interval value. It appears the model calculated values provide a slightly larger 95% prediction interval than the calculations I performed. That being said, the intervals are very similar.

# Exercise 8.5

Data set `global_economy` contains the annual Exports from many countries. Select one country to analyse.

```{r warning=F, message=F}
fra_exports <- global_economy %>%
  filter(Country == 'France')

# Selected France for no particular reason besides it contains data for the entirety of the defined time series.
head(fra_exports)
```

Selected France for no particular reason besides it is not the United States and contains data for the entirety of the defined time series.

## Section a

Plot the Exports series and discuss the main features of the data.

```{r warning=F, message=F}
# Exports:	Exports of goods and services (% of GDP).
fra_exports %>%
  autoplot(Exports) +
  labs(y="% of GDP", title="Exports: France") +
  guides(colour = "none")
```

**Main features:** Overall, there appears to be an upward trend in the Exports, but I do not see any seasonality, nor cyclic nature to the time series. Departing from the overall upward trend, a dip appears between 1960 and 1970. And dip occurs between 1985 and 1998. Also, a very distinct negative spike occurs between 2008 and 2011.

## Section b

Use an ETS(A,N,N) model to forecast the series, and plot the forecasts.

```{r warning=F, message=F}
# Estimate parameters
fit <- fra_exports %>%
  model(ETS(Exports ~ error("A") + trend("N") + season("N")))

report(fit)

# Set the forecast to 10 for 10 years
fc <- fit %>%
  forecast(h = 10)

fc %>%
  autoplot(fra_exports) +
  labs(y="% of GDP", title="Exports: France") +
  guides(colour = "none")
```

Above plot shows the forecast for the next 10 years. The forecast value is 30.9(%) as noted below in the tsibble output.

```{r warning=F, message=F}
head(fc)
```

## Section c

Compute the RMSE values for the training data.

```{r warning=F, message=F}
fit_acc <- accuracy(fit)

fit_acc
```

The RMSE of the training data for the ETS(A,N,N) model is 1.15.

## Section d

Compare the results to those from an ETS(A,A,N) model. (Remember that the trended model is using one more parameter than the simpler model.) Discuss the merits of the two forecasting methods for this data set.

```{r warning=F, message=F}
fit_2 <- fra_exports %>%
  model(ETS(Exports ~ error("A") + trend("A") + season("N")))

fit_2_acc <- accuracy(fit_2)
fit_2_acc
```

The RMSE of the training data for the ETS(A,A,N) model is 1.12. A slightly better performance by the ETS(A,A,N) model over the ETS(A,N,N) model. Not a surprising result, as the ETS(A,A,N) model takes into account trending, which the initial plot of Exports clearly indicated.

## Section e

Compare the forecasts from both methods. Which do you think is best?

```{r warning=F, message=F}
# Set the forecast to 10 for 10 years
fc_2 <- fit_2 %>%
  forecast(h = 10)

fc_2 %>%
  autoplot(fra_exports) +
  labs(y="% of GDP", title="Exports: France") +
  guides(colour = "none")
```

The above plot shows the forecasted values for the ETS(A,A,N) model.

```{r warning=F, message=F}
fc_2
```

As noted in Section B, the forecast values for the ETS(A,N,N) model is the same value 30.9 for every year forward. As the above plot and forecast values for the ETS(A,A,N) model shows, the forecasted values for ETS(A,A,N) increases due to the additive trend parameter. The constant increase for this model of 0.3 does visually appear more in line with the increasing trend of the Exports data.

## Section f

Calculate a 95% prediction interval for the first forecast for each model, using the RMSE values and assuming normal errors. Compare your intervals with those produced using R.

```{r warning=F, message=F}
# 95% prediction interval for the first forecast: ETS(A,N,N)
y_hat <- fc$.mean[1]

lower_limit_95_fc <- y_hat - (fit_acc$RMSE * 1.96)
upper_limit_95_fc <- y_hat + (fit_acc$RMSE * 1.96)

ets_ann_interval <- c(lower_limit_95_fc, upper_limit_95_fc)

ets_ann_interval
```

Above is the calculated 95% interval for the ETS(A,N,N) model.

```{r warning=F, message=F}
# 95% prediction interval for the second forecast: ETS(A,A,N)
y_hat_2 <- fc_2$.mean[1]

lower_limit_95_fc2 <- y_hat_2 - (fit_2_acc$RMSE * 1.96)
upper_limit_95_fc2 <- y_hat_2 + (fit_2_acc$RMSE * 1.96)

ets_aan_interval <- c(lower_limit_95_fc2, upper_limit_95_fc2)

ets_aan_interval
```

Above is the calculated 95% interval for the ETS(A,A,N) model.

```{r warning=F, message=F}
# Determine the model forecast 95% intervals
fc_hilo <- fc %>% hilo()

# Output model interval values
fc_hilo$`95%`[1]
```

Above is the 95% interval for the ETS(A,N,N) model produced by R. The R produced values are 0.04 lower for the lower limit and 0.04 higher for the higher limit.

```{r warning=F, message=F}
# Determine the model forecast 95% intervals
fc_2_hilo <- fc_2 %>% hilo()

# Output model interval values
fc_2_hilo$`95%`[1]
```

Above is the 95% interval for the ETS(A,A,N) model produced by R. The R produced values are 0.08 lower for the lower limit and 0.08 higher for the higher limit.

As noted in Exercise 8.1 the R produced confidence intervals appear a bit broader than the calculated values, but given the small differences, the calculated and R produced confidence intervals do appear in line with each other.

# Exercise 8.6

Forecast the Chinese GDP from the `global_economy` data set using an ETS model. Experiment with the various options in the `ETS()` function to see how much the forecasts change with damped trend, or with a Box-Cox transformation. Try to develop an intuition of what each is doing to the forecasts.

[Hint: use a relatively large value of `h` when forecasting, so you can clearly see the differences between the various options when plotting the forecasts.]

```{r warning=F, message=F}
chn_gdp <- global_economy %>%
  filter(Country == 'China') %>%
  mutate(GDP = GDP/1e9) %>%
  select(c(Country, Code, Year, GDP))

(chn_gdp)

# GDP:	Gross domestic product (in $USD February 2019).
chn_gdp %>%
  autoplot(GDP) +
  labs(y="Billions $USD", title="GDP: China") +
  guides(colour = "none")
```

Above plot shows the Chinese GDP for initial visual inspection and understanding of the data.

```{r warning=F, message=F}
fit <- chn_gdp %>%
  model(
    SES = ETS(GDP ~ error("A") + trend("N") + season("N")),
    Holt = ETS(GDP ~ error("A") + trend("A") + season("N")),
    Damped = ETS(GDP ~ error("A") + trend("Ad") + season("N"))
  )

# Forecast for 20 years
fc <- fit %>% forecast(h = 20)

fc %>%
  autoplot(chn_gdp, level=NULL) +
  labs(y="Billions $USD", title="GDP: China") +
  guides(colour = guide_legend(title = "Forecast"))
```

Above plot shows the forecasted values for the next 20 years of the Chinese GDP. The simple exponential smoothing forecast, as expected, produces a horizontal line which doesn't appear to follow the increasing trend. The Holt forecast shows an increasing forecast with constant growth. And the Holt dampened forecast shows increasing trend that does slow over time. The Holt dampened forecast appears the most realistic of the three given it would be unlikely for the Chinese GDP to grow at a constant rate for 20 years.

```{r warning=F, message=F}
# Calculate lambda for Box-Cox
lambda <- chn_gdp %>%
  features(GDP, features = guerrero) %>%
  pull(lambda_guerrero)

fit_bc <- chn_gdp %>%
  model(
    SES = ETS(box_cox(GDP, lambda) ~ error("A") + trend("N") + season("N")),
    Holt = ETS(box_cox(GDP, lambda) ~ error("A") + trend("A") + season("N")),
    Damped = ETS(box_cox(GDP, lambda) ~ error("A") + trend("Ad") + season("N"))
  )

# Forecast for 20 years
fc_bc <- fit_bc %>% forecast(h = 20)

fc_bc %>%
  autoplot(chn_gdp, level=NULL) +
  labs(y = "",
       title = latex2exp::TeX(paste0(
         "Transformed China GDP with $\\lambda$ = ",
         round(lambda,2)))) +
  guides(colour = guide_legend(title = "Forecast"))
```

Now, applying the Box-Cox transformation along with the ETS() function produces some interesting results. But first, in the not-so surprising result, the simple exponential smoothing model produced a horizontal line. The Holt approach produced a forecast that follows an exponential growth that clearly takes off after 5 years. The dampened method also starts to increase but not quite at the rate of the Holt method. 

Given the 6 forecasts above, I personally would select the dampened method on the non-transformed data. I'm not expert on the Chinese economy, but the continue growth rate seems difficult to maintain according to the Hold method forecast.

# Exercise 8.7

Find an ETS model for the Gas data from `aus_production` and forecast the next few years. Why is multiplicative seasonality necessary here? Experiment with making the trend damped. Does it improve the forecasts?

```{r warning=F, message=F}
# Gas:	Gas production in petajoules.
aus_gas <- aus_production %>%
  select(Quarter, Gas)

aus_gas %>%
  autoplot(Gas)

fit <- aus_gas %>%
  model(
    add = ETS(Gas ~ error("A") + trend("A") + season("N")),
    mult = ETS(Gas ~ error("M") + trend("A") + season("N")),
    add_sea = ETS(Gas ~ error("A") + trend("A") + season("A")),
    mult_sea = ETS(Gas ~ error("M") + trend("A") + season("M")),
    mult_sea_damp = ETS(Gas ~ error("M") + trend("Ad") + season("M"))
  )

# Forecast for 5 years (interval is quarters)
fc <- fit %>% forecast(h = 20)

fc %>%
  autoplot(aus_gas, level=NULL) +
  labs(y="Petajoules", title="Gas Production: Australia") +
  guides(colour = guide_legend(title = "Forecast"))
```

Multiplicative seasonality is  necessary

# Exercise 8.8

Recall your retail time series data (from Exercise 8 in Section 2.10).

```{r warning=F, message=F}
set.seed(8675309)

myseries <- aus_retail %>%
  filter(`Series ID` == sample(aus_retail$`Series ID`,1))

head(myseries)
```

## Section a

Why is multiplicative seasonality necessary for this series?

**Answer**: XXX

## Section b

Apply Holt-Winters’ multiplicative method to the data. Experiment with making the trend damped.

```{r warning=F, message=F}
fit_ms <- myseries %>%
  model(
    M_S = ETS(Turnover ~ error("M") + trend("A") + season("M")),
    M_S_D = ETS(Turnover ~ error("M") + trend("Ad") + season("M"))
  )

# Forecast for 5 years (interval is monthly)
fc_ms <- fit_ms %>% forecast(h = 60)

fc_ms %>%
  autoplot(myseries, level=NULL) +
  labs(y="$Million AUD", title="Retail Turnover: Australia") +
  guides(colour = guide_legend(title = "Forecast"))
```

## Section c

Compare the RMSE of the one-step forecasts from the two methods. Which do you prefer?

```{r warning=F, message=F}
acc_fit <- accuracy(fit_ms)

acc_fit
```

## Section d

Check that the residuals from the best method look like white noise.

```{r warning=F, message=F}
aug_fit <- augment(fit_ms)

#msd <- fit_ms %>%
#  filter(.model == "M_S_D") %>%
#  gg_tsresiduals()

#model <- fit_ms$M_S_D
#m <- mable(fit_ms$M_S_D)
#m %>% gg_tsresiduals()

fit_msd <- myseries %>%
  model(ETS(Turnover ~ error("M") + trend("Ad") + season("M")))

# fit_msd

fit_msd %>% gg_tsresiduals()
```

## Section e

Now find the test set RMSE, while training the model to the end of 2010. Can you beat the seasonal naïve approach from Exercise 7 in Section 5.11?

```{r warning=F, message=F}
# Define training set
myseries_train <- myseries %>%
  filter(year(Month) < 2011)

# lambda from Assignment 2
lambda <- 0.24

fit <- myseries_train %>%
  model(SNAIVE(box_cox(Turnover, lambda) ~ drift()))

# Check residuals
fit %>% gg_tsresiduals()

fc <- fit %>%
  forecast(new_data = anti_join(myseries, myseries_train))
fc %>% autoplot(myseries)

fit %>% accuracy()

fc %>% accuracy(myseries)

# All above from the exercise in Chapter 5

fit_msd_train <- myseries_train %>%
  model(ETS(Turnover ~ error("M") + trend("Ad") + season("M")))

fc_msd <- fit_msd_train %>%
  forecast(new_data = anti_join(myseries, myseries_train))

fc_msd %>% autoplot(myseries)

fit_msd_train %>% accuracy()

fc_msd %>% accuracy(myseries)
```

# Exercise 8.9

For the same retail data, try an STL decomposition applied to the Box-Cox transformed series, followed by ETS on the seasonally adjusted data. How does that compare with your best previous forecasts on the test set?

```{r warning=F, message=F}
# Initial STL decomposition on the data (no Box-Cox)
myseries_stl <- myseries_train %>% 
  model(stl = STL(Turnover))

components(myseries_stl) %>% autoplot()

# STL on box-cox transformation
myseries_stl_bc <- myseries_train %>% 
  model(stl = STL(box_cox(Turnover, lambda)))

components(myseries_stl_bc) %>% autoplot()
```


```{r warning=F, message=F}
# Now apply the ETS
my_series_bc_ets_fit <- myseries_train %>%
  model(ETS(box_cox(Turnover, lambda)))

my_series_bc_ets_fc <- my_series_bc_ets_fit %>%
  forecast(new_data = anti_join(myseries, myseries_train))

my_series_bc_ets_fc %>% autoplot(myseries)

my_series_bc_ets_fc %>% accuracy(myseries)
```

