---
title: "DATA 624 Project 1 v1"
subtitle: "CUNY Fall 2021"
author: "Philip Tanofsky"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Looking over previous homeworks to identify different forecasting approaches

- Box-cox transformations

- decomposition


```{r warning=F, message=F}
# Import required R libraries
library(fpp3)
library(tidyverse)
library(readxl)
```

This project consists of 3 parts - two required and one bonus and is worth 15% of your grade.  The project is due at 11:59 PM on Sunday October 31.  I will accept late submissions with a penalty until the meetup after that when we review some projects.

# Part A – ATM Forecast

- Dataset: ATM624Data.xlsx

In part A, I want you to forecast how much cash is taken out of 4 different ATM machines for May 2010.  The data is given in a single file.  The variable `Cash` is provided in hundreds of dollars, other than that it is straight forward. I am being somewhat ambiguous on purpose to make this have a little more business feeling. Explain and demonstrate your process, techniques used and not used, and your actual forecast. I am giving you data via an Excel file, please provide your written report on your findings, visuals, discussion and your R code via an RPubs link along with the actual.rmd file  Also please submit the forecast which you will put in an Excel readable file.

```{r warning=F, message=F}
# Read in data
atm_data_raw <- read_excel("data/ATM624Data.xlsx")

df  <- data.frame(StartDate  =c("9/14/2019 10:18:59 AM","9/14/2019 3:18:59 PM"), 
                  EndDate= c("9/18/2019 2:27:14 AM","9/18/2019 1:27:14 PM"))

atm_data_raw <- atm_data_raw %>% mutate(DATE = as.Date(DATE, origin = "1899-12-30"))

# Initial output to see data
head(atm_data_raw)

summary(atm_data_raw)

dim(atm_data_raw)
# 1474    3
#Cash in hundreds

# Define as tsibble
atm_data_ts <- atm_data_raw %>%
  as_tsibble(index = DATE, key = ATM)

atm_data_ts
```

```{r warning=F, message=F}
library(seasonal)
atm1_data_ts <- atm_data_ts %>%
  filter(ATM == 'ATM1')

summary(atm1_data_ts)

atm1_data_ts

atm1_data_ts %>%
  autoplot(Cash)

# Calculate median value for ATM1
median <- median(atm1_data_ts$Cash, na.rm=TRUE)

# Set NAs to median
atm1_data_ts$Cash[is.na(atm1_data_ts$Cash)] <- median

summary(atm1_data_ts)

head(atm1_data_ts)
```



```{r warning=F, message=F}

atm1_data_ts <- atm1_data_ts %>%
  mutate(DATE = as_date(DATE)) %>%
  update_tsibble(index = DATE)

atm1_data_ts
```




```{r warning=F, message=F}
# From: https://stats.stackexchange.com/questions/494013/control-the-period-for-daily-time-series-in-tsibbles
atm1_dcmp <- atm1_data_ts %>%
  model(stl = STL(Cash ~ trend(window=Inf) + season(period=7, window="periodic"))) 

atm1_dcmp %>% components() %>% autoplot()


components(atm1_dcmp) %>%
  as_tsibble() %>%
  autoplot(Cash, colour = "gray") +
  geom_line(aes(y=season_adjust), colour = "#0072B2") +
  labs(y = "Cash (in hundreds)", title = "Seasonally Adjusted Trendline")

# from textbook: If the seasonal component is removed from the original data, the resulting values are the “seasonally adjusted” data.
```

```{r warning=F, message=F}
# Create training set (365 total, perhaps assume 1 year of data)
# 292 days, yes, using the generating dates based on the integer values


train_atm1 <- atm1_data_ts %>% 
  filter_index("2009-05-01" ~ "2010-02-17")

train_atm1

# Fit the models
fit_atm1 <- train_atm1 %>%
  model(
    Naive = NAIVE(Cash),
    `Seasonal naive` = SNAIVE(Cash),
    `Random walk` = RW(Cash ~ drift())
  )

fit_atm1_snaive <- train_atm1 %>%
  model(SNAIVE(Cash))

fit_atm1 %>% accuracy()

# Check the residuals of Seasonal Naive
fit_atm1_snaive %>% gg_tsresiduals()

# Generate forecasts for 73 days
fc_atm1 <- fit_atm1 %>% forecast(h = "71 days")

fc_atm1 %>% accuracy(atm1_data_ts)

# Plot forecasts against actual values
fc_atm1 %>%
  autoplot(train_atm1, level = NULL) +
  autolayer(
    filter_index(atm1_data_ts, "2010-02-18" ~ "2010-04-30"),
    colour = "black"
  ) +
  labs(
    y = "Cash (in hundreds)",
    title = "Forecasts for ATM1 Withdrawals"
  ) +
  guides(colour = guide_legend(title = "Forecast"))


# Result: Not good, SNAIVE at least attempts the seasonal nature
```



```{r warning=F, message=F}
# ETS

fit_atm1_ets <- train_atm1 %>%
  model(
    add = ETS(Cash ~ error("A") + trend("N") + season("A")),
    mult = ETS(Cash ~ error("M") + trend("N") + season("M")),
    damp = ETS(Cash ~ error("M") + trend("Ad") + season("M"))
  )

# Forecast for 73 days
fc_atm1_ets <- fit_atm1_ets %>% forecast(h = "71 days")

fc_atm1_ets %>%
  autoplot(filter_index(train_atm1, "2009-12-01" ~ "2010-04-30"), level = NULL) +
  autolayer(
    filter_index(atm1_data_ts, "2009-12-01" ~ "2010-04-30"),
    colour = "black"
  ) +
  labs(y="Billions $USD", title="GDP: China") +
  guides(colour = guide_legend(title = "Forecast"))
# Forecast over the test set
# Measure the accuracy
# Forecast beyond the data
# NAIVE
# SNAIVE
# drift()
# ETS
# ARIMA

```

```{r warning=F, message=F}
atm2_data_ts <- atm_data_ts %>%
  filter(ATM == 'ATM2')

atm2_data_ts %>%  autoplot(Cash)

# Calculate median value for ATM2
median <- median(atm2_data_ts$Cash, na.rm=TRUE)

# Set NAs to median
atm2_data_ts$Cash[is.na(atm2_data_ts$Cash)] <- median

summary(atm2_data_ts)

atm2_data_ts %>%
  model(stl = STL(Cash ~ trend(window=Inf) + season(period=7, window="periodic"))
        ) %>% 
  components() %>% autoplot()
```

```{r warning=F, message=F}
atm3_data_ts <- atm_data_ts %>%
  filter(ATM == 'ATM3', Cash > 0)

atm3_data_ts %>% autoplot(Cash)

summary(atm3_data_ts)


# Literally just 3 values above 0
```

```{r warning=F, message=F}
atm4_data_ts <- atm_data_ts %>%
  filter(ATM == 'ATM4')

atm4_data_ts %>% autoplot(Cash)

summary(atm4_data_ts)

atm4_data_ts %>%
  model(stl = STL(Cash ~ trend(window=Inf) + season(period=7, window="periodic"))
        ) %>% 
  components() %>% autoplot()
```


Summary output
      DATE           ATM                 Cash        
 Min.   :39934   Length:1474        Min.   :    0.0  
 1st Qu.:40026   Class :character   1st Qu.:    0.5  
 Median :40118   Mode  :character   Median :   73.0  
 Mean   :40118                      Mean   :  155.6  
 3rd Qu.:40210                      3rd Qu.:  114.0  
 Max.   :40312                      Max.   :10919.8  
                                    NA's   :19       

Date 39934 to 40312

379 dates

ATM1, ATM2, ATM3, ATM4, NA

Cash 19 NA's

Data observations:
ATM1: 3 Cash NA values
ATM2: 2 Cash NA values
ATM3: Only 3 Cash values with something above zero
ATM4: Many Cash values with a decimal, but not all, something weird there, also ATM4 appears to have 1 really crazy outlier
Final 14 entries are NA, NA (DATE of 40299 and higher are NA, NA)

Dimensions output
[1] 1474    3

So remove the last 14 and all that remains is 1460. And 1460 / 4 is 365, so thus one year.


# Part B – Forecasting Power

- Dataset: ResidentialCustomerForecastLoad-624.xlsx

Part B consists of a simple dataset of residential power usage for January 1998 until December 2013.  Your assignment is to model these data and a monthly forecast for 2014. The data is given in a single file. The variable ‘KWH’ is power consumption in Kilowatt hours, the rest is straight forward. Add this to your existing files above. 

```{r warning=F, message=F}
# Read in data
power_data_raw <- read_excel("data/ResidentialCustomerForecastLoad-624.xlsx")

# Change column name to 'Month'
names(power_data_raw)[names(power_data_raw) == 'YYYY-MMM'] <- 'Month'

# Display first 5 rows for visual inspection
head(power_data_raw)

# Display summary for initial assessment
summary(power_data_raw)

# Display dimensions for assessment
# should be 16 years of data 1998-2013
# Yep, 192/12 = 16
dim(power_data_raw)
# 192   3
# KWH

power_data_ts <- power_data_raw %>%
  mutate(Month = yearmonth(Month)) %>%
  mutate(KWH = KWH/1e3) %>% # In thousands
  as_tsibble(index = Month)

# Output first 5 rows of tsibble
head(power_data_ts)

# Inital plot of data
power_data_ts %>%
  autoplot(KWH)

power_data_ts %>%
  filter_index("2010" ~ "2011") %>%
  print()
```

First observations, data is Monthly, so I'd expect a seasonal component.
1 month is missing KWH has 1 NA value (2008 Sep) Considering imputing with median Sep Value
Outlier (with very small value in July 2010) Considering imputing with median Jul Value

```{r warning=F, message=F}
power_data_ts

library(stringr)
# I want all the September values
sep_data <- power_data_ts %>%
  filter(str_detect(Month, "Sep"))

sep_data <- as_tibble(sep_data)

sep_kwh_med <- sep_data %>% 
  summarise(Median = median(KWH, na.rm = TRUE))

sep_kwh_med
# Median 7666.97
#power_data_ts[power_data_ts$Month == "2008 Sep"] <- sep_kwh_med

power_data_ts[129, 3] <- sep_kwh_med

power_data_ts
```

```{r warning=F, message=F}
# I want all the July values
jul_data <- power_data_ts %>%
  filter(str_detect(Month, "Jul"))

jul_data <- as_tibble(jul_data)

jul_kwh_med <- jul_data %>% 
  summarise(Median = median(KWH, na.rm = TRUE))

jul_kwh_med
# Median 7678.623	

power_data_ts[151, 3] <- jul_kwh_med

power_data_ts %>% autoplot(KWH)
```

```{r warning=F, message=F}
# STL
power_data_ts %>%
  model(stl = STL(KWH ~ trend(window=Inf) + season(period=12, window="periodic"))) %>% 
  components() %>% autoplot()
```

```{r warning=F, message=F}

power_dcmp <- power_data_ts %>%
  model(stl = STL(KWH ~ trend(window=Inf) + season(period=12, window="periodic"))) 

power_dcmp %>% components() %>% autoplot()

components(power_dcmp) %>%
  as_tsibble() %>%
  autoplot(KWH, colour = "gray") +
  geom_line(aes(y=season_adjust), colour = "#0072B2") +
  labs(y = "KWH (in thousands)", title = "Seasonally Adjusted Trendline")

# from textbook: If the seasonal component is removed from the original data, the resulting values are the “seasonally adjusted” data.
```

```{r warning=F, message=F}
# Seasonal differencing
power_data_ts %>%
  gg_tsdisplay(difference(KWH, 12),
               plot_type='partial', lag=36) +
  labs(title="Seasonally differenced", y="")


# ARIMA model
#power_data_ts %>% gg_tsdisplay()

# https://otexts.com/fpp3/seasonal-arima.html
arima_mod_power <- power_data_ts %>% model(ARIMA(KWH, stepwise=F, approx=F))

report(arima_mod_power)

arima_mod_power %>% gg_tsresiduals(lag=36)

forecast(arima_mod_power, h=36) %>%
  autoplot(power_data_ts) +
  labs(title = "KWH Used",
       y="KWH (in thousands)")
```

```{r warning=F, message=F}
# Forecasting
```

# Part C – Waterflow (optional)

- Dataset: Waterflow_Pipe1.xlsx and Waterflow_Pipe2.xlsx

Part C consists of two data sets.  These are simple 2 columns sets, however they have different time stamps.  Your optional assignment is to time-base sequence the data and aggregate based on hour (example of what this looks like, follows).  Note for multiple recordings within an hour, take the mean.  Then to determine if the data is stationary and can it be forecast.  If so, provide a week forward forecast and present results via Rpubs and .rmd and the forecast in an Excel readable file. 

```{r warning=F, message=F}

```

```{r warning=F, message=F}
# Read in data
pipe1_data_raw <- read_excel("data/Waterflow_Pipe1.xlsx")
pipe2_data_raw <- read_excel("data/Waterflow_Pipe2.xlsx")

# Initial output to see data
head(pipe1_data_raw)
head(pipe2_data_raw)

summary(pipe1_data_raw)
summary(pipe2_data_raw)

dim(pipe1_data_raw)
dim(pipe2_data_raw)
# 1474    3
#Cash in hundreds
```
# Define as tsibble
atm_data_ts <- atm_data_raw %>%
  as_tsibble(index = DATE, key = ATM)

atm_data_ts
```




#30#


```{r warning=F, message=F}

```

```{r warning=F, message=F}

```

```{r warning=F, message=F}

```


```{r warning=F, message=F}

```












